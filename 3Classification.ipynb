{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Exploiting Sentinel-1 imagery time series to detect grasslands in northern Brazil tropical plains</center> </h1>\n",
    "<h3> <center> Part 3 - Classification </center> </h3>\n",
    "<center> Arian Ferreira Carneiro </center>\n",
    "<center>Willian Vieira de Oliveira </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from osgeo import gdal, gdal_array\n",
    "#from osgeo import osr\n",
    "from numpy import genfromtxt\n",
    "\n",
    "# Load scikit's random forest classifier library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_files = 'YES'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files that contain the pixel values of the area to be classified, the samples and their respective classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories for the input files\n",
    "dir_NL_pixels = \"OUTPUT/NL.csv\"\n",
    "dir_NL_samples = \"OUTPUT/NL_AllSamples_pValues.csv\"\n",
    "dir_NL_classes = \"OUTPUT/NL_AllSamples_classes.csv\"\n",
    "\n",
    "dir_Ratio_pixels = \"OUTPUT/Ratio.csv\"\n",
    "dir_Ratio_samples = \"OUTPUT/Ratio_AllSamples_pValues.csv\"\n",
    "dir_Ratio_classes = \"OUTPUT/Ratio_AllSamples_classes.csv\"\n",
    "\n",
    "dir_RGI_pixels = \"OUTPUT/RGI.csv\"\n",
    "dir_RGI_samples = \"OUTPUT/RGI_AllSamples_pValues.csv\"\n",
    "dir_RGI_classes = \"OUTPUT/RGI_AllSamples_classes.csv\"\n",
    "\n",
    "dir_VH_pixels = \"OUTPUT/VH.csv\"\n",
    "dir_VH_samples = \"OUTPUT/VH_AllSamples_pValues.csv\"\n",
    "dir_VH_classes = \"OUTPUT/VH_AllSamples_classes.csv\"\n",
    "\n",
    "dir_VV_pixels = \"OUTPUT/VV.csv\"\n",
    "dir_VV_samples = \"OUTPUT/VV_AllSamples_pValues.csv\"\n",
    "dir_VV_classes = \"OUTPUT/VV_AllSamples_classes.csv\"\n",
    "\n",
    "# Lists of the directories\n",
    "filenames_C1 = ['NL', 'Ratio', 'RGI', 'VH', 'VV']\n",
    "list_pixels_C1 = [dir_NL_pixels, dir_Ratio_pixels, dir_RGI_pixels, dir_VH_pixels, dir_VV_pixels]\n",
    "list_samples_C1 = [dir_NL_samples, dir_Ratio_samples, dir_RGI_samples, dir_VH_samples, dir_VV_samples]\n",
    "list_classes_C1 = [dir_NL_classes, dir_Ratio_classes, dir_RGI_classes, dir_VH_classes, dir_VV_classes]\n",
    "\n",
    "dir_output_pixels = \"OUTPUT/Classification_pixelValues/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files that contain the metrics computed for the pixels to be classified, the samples and their respective classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories for the input files\n",
    "dir_NL_metrics = \"OUTPUT/NL_metrics.csv\"\n",
    "dir_NL_samples = \"OUTPUT/NL_AllSamples_metrics.csv\"\n",
    "dir_NL_classes = \"OUTPUT/NL_AllSamples_classes.csv\"\n",
    "\n",
    "dir_Ratio_metrics = \"OUTPUT/Ratio_metrics.csv\"\n",
    "dir_Ratio_samples = \"OUTPUT/Ratio_AllSamples_metrics.csv\"\n",
    "dir_Ratio_classes = \"OUTPUT/Ratio_AllSamples_classes.csv\"\n",
    "\n",
    "dir_RGI_metrics = \"OUTPUT/RGI_metrics.csv\"\n",
    "dir_RGI_samples = \"OUTPUT/RGI_AllSamples_metrics.csv\"\n",
    "dir_RGI_classes = \"OUTPUT/RGI_AllSamples_classes.csv\"\n",
    "\n",
    "dir_VH_metrics = \"OUTPUT/VH_metrics.csv\"\n",
    "dir_VH_samples = \"OUTPUT/VH_AllSamples_metrics.csv\"\n",
    "dir_VH_classes = \"OUTPUT/VH_AllSamples_classes.csv\"\n",
    "\n",
    "dir_VV_metrics = \"OUTPUT/VV_metrics.csv\"\n",
    "dir_VV_samples = \"OUTPUT/VV_AllSamples_metrics.csv\"\n",
    "dir_VV_classes = \"OUTPUT/VV_AllSamples_classes.csv\"\n",
    "\n",
    "# Lists of the directories\n",
    "filenames_C2 = ['NL', 'Ratio', 'RGI', 'VH', 'VV']\n",
    "list_metrics_C2 = [dir_NL_metrics, dir_Ratio_metrics, dir_RGI_metrics, dir_VH_metrics, dir_VV_metrics]\n",
    "list_samples_C2 = [dir_NL_samples, dir_Ratio_samples, dir_RGI_samples, dir_VH_samples, dir_VV_samples]\n",
    "list_classes_C2 = [dir_NL_classes, dir_Ratio_classes, dir_RGI_classes, dir_VH_classes, dir_VV_classes]\n",
    "\n",
    "dir_output_metrics = \"OUTPUT/Classification_metrics/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary functions\n",
    "\n",
    "### Function to write each classification map to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Write_GeoTiff(file, filename, Nrows, Ncols, geotransform, projection):\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    \n",
    "    dataset_output = driver.Create(filename, Ncols, Nrows, 1, gdal.GDT_Float32)\n",
    "    dataset_output.GetRasterBand(1).WriteArray(file)\n",
    "    \n",
    "    if geotransform is not None:\n",
    "        gt = list(geotransform)\n",
    "        dataset_output.SetGeoTransform(tuple(gt))\n",
    "    dataset_output.SetProjection(projection)\n",
    "    \n",
    "    dataset_output = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification 1: using pixel values\n",
    "\n",
    "In this procedure, we perform the classification of the data cube considering the time series of pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying the  NL  data cube...\n",
      "    Overall accuracy (resubst): 0.9499\n",
      "    Overall accuracy (holdout): 0.861\n",
      "    The products were written to file!\n",
      "\n",
      "\n",
      "Classifying the  Ratio  data cube...\n",
      "    Overall accuracy (resubst): 0.9337\n",
      "    Overall accuracy (holdout): 0.7587\n",
      "    The products were written to file!\n",
      "\n",
      "\n",
      "Classifying the  RGI  data cube...\n",
      "    Overall accuracy (resubst): 0.9391\n",
      "    Overall accuracy (holdout): 0.7172\n",
      "    The products were written to file!\n",
      "\n",
      "\n",
      "Classifying the  VH  data cube...\n",
      "    Overall accuracy (resubst): 0.9507\n",
      "    Overall accuracy (holdout): 0.8542\n",
      "    The products were written to file!\n",
      "\n",
      "\n",
      "Classifying the  VV  data cube...\n",
      "    Overall accuracy (resubst): 0.9383\n",
      "    Overall accuracy (holdout): 0.8475\n",
      "    The products were written to file!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#for i in range(1):\n",
    "for i in range(len(filenames_C1)):\n",
    "    print(\"Classifying the \", filenames_C1[i], \" data cube...\")\n",
    "    \n",
    "    pixel_values = pd.read_csv(list_pixels_C1[i])\n",
    "    sample_values = pd.read_csv(list_samples_C1[i])\n",
    "    sample_values = sample_values.drop(labels='Class', axis=1) # removing the column 'Class' from the dataframe\n",
    "    sample_classes = pd.read_csv(list_classes_C1[i])\n",
    "    \n",
    "    smp_values = np.float32(sample_values)\n",
    "    smp_classes = np.float32(sample_classes)\n",
    "    smp_classes = np.ravel(smp_classes) # converting from column-vector to 1d array (expected by the classifier)\n",
    "    pixels_values = np.float32(pixel_values)\n",
    "    \n",
    "    # ------------------------- SPLITTING THE SAMPLES INTO TRAINING AND TESTING DATASETS -------------------------\n",
    "    \n",
    "    # This scikit-learn function separates the datasets in train and test samples\n",
    "    smp_values_train, smp_values_test, smp_classes_train, smp_classes_test = train_test_split(smp_values, smp_classes, \n",
    "                                                                                                test_size=0.3)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=300, min_samples_leaf = 5, max_features = 5, n_jobs=-1, oob_score=True)\n",
    "    rf.fit(smp_values_train, smp_classes_train) # X and Y parameters (as recognized by the classifier)\n",
    "    \n",
    "    Y_train_pred = rf.predict(smp_values_train) # Classifies the training samples (resubstitution validation technique)\n",
    "    acc_train = accuracy_score(smp_classes_train, Y_train_pred) # Computes the accuracy\n",
    "    print('    Overall accuracy (resubst): ' + str(round(acc_train,4)))\n",
    "    #print('-------------------')\n",
    "    \n",
    "    Y_test_pred = rf.predict(smp_values_test) # Classifies the testing samples (hold-out validation technique)\n",
    "    acc_test = accuracy_score(smp_classes_test, Y_test_pred) # Computes the accuracy\n",
    "    print('    Overall accuracy (holdout): ' + str(round(acc_test,4)))\n",
    "    confusion_pred = pd.crosstab(Y_test_pred, smp_classes_test, rownames=['Pred'], colnames=['Actual'], \n",
    "                                 margins=False, margins_name=\"Total\") # confusion matrix for the testing dataset\n",
    "    \n",
    "    confusion_pred.loc['Accuracies','OA_Resubs'] = acc_train\n",
    "    confusion_pred.loc['Accuracies','OA_Holdout'] = acc_test\n",
    "\n",
    "    # -----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    class_pred = rf.predict(pixels_values) #classification of all pixels\n",
    "    \n",
    "    imgPath = \"DATA/ee_export/\" + filenames_C1[i] + \".tif\"\n",
    "    example_img = gdal.Open(imgPath)\n",
    "\n",
    "    Nrows = example_img.RasterYSize\n",
    "    Ncols = example_img.RasterXSize\n",
    "    GeoTransform = example_img.GetGeoTransform()\n",
    "    Projection = example_img.GetProjection()\n",
    "\n",
    "    example_img = None\n",
    "\n",
    "    classif_array = np.reshape(class_pred, (Nrows-6, Ncols-6))\n",
    "\n",
    "    # In this study, we disconsidered the border pixels (3-pixel length). Therefore, we need to adjust \n",
    "    # the array to follow the same characteristics of the example image (GeoTranform and Projection)\n",
    "    classif_array_adjusted = np.empty((Nrows, Ncols), np.float32)\n",
    "    classif_array_adjusted[3:Nrows-3, 3:Ncols-3] = classif_array\n",
    "\n",
    "    # Writing the classification product and the confusion matrix to files\n",
    "    if (write_files == 'YES'):\n",
    "        filename_map = dir_output_pixels + filenames_C1[i] + \"_Pixels_RFclassification.tif\"\n",
    "        filename_matrix = dir_output_pixels + filenames_C1[i] + \"_Pixels_RFconfusionMatrix.csv\"\n",
    "\n",
    "        try:\n",
    "            # Classification map\n",
    "            Write_GeoTiff(classif_array_adjusted, filename_map, Nrows, Ncols, GeoTransform, Projection)\n",
    "            \n",
    "            # Confusion matrix\n",
    "            confusion_pred.to_csv(filename_matrix, sep=',', index=True, header=True, index_label='Pred/Actual', \n",
    "                                  encoding='utf-8-sig')\n",
    "            print(\"    The products were written to file!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification 2: using basic metrics\n",
    "\n",
    "In this procedure, we perform the classification of the data cube considering the metrics computed for the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying the  NL  data cube...\n",
      "    Overall accuracy (resubst): 0.911\n",
      "    Overall accuracy (holdout): 0.8407\n",
      "    The products were written to file!\n",
      "\n",
      "\n",
      "Classifying the  Ratio  data cube...\n",
      "    Overall accuracy (resubst): 0.8803\n",
      "    Overall accuracy (holdout): 0.666\n",
      "    The products were written to file!\n",
      "\n",
      "\n",
      "Classifying the  RGI  data cube...\n",
      "    Overall accuracy (resubst): 0.8758\n",
      "    Overall accuracy (holdout): 0.64\n",
      "    The products were written to file!\n",
      "\n",
      "\n",
      "Classifying the  VH  data cube...\n",
      "    Overall accuracy (resubst): 0.9118\n",
      "    Overall accuracy (holdout): 0.8301\n",
      "    The products were written to file!\n",
      "\n",
      "\n",
      "Classifying the  VV  data cube...\n",
      "    Overall accuracy (resubst): 0.8994\n",
      "    Overall accuracy (holdout): 0.8127\n",
      "    The products were written to file!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#for i in range(1):\n",
    "for i in range(len(filenames_C2)):\n",
    "    print(\"Classifying the \", filenames_C2[i], \" data cube...\")\n",
    "    \n",
    "    pixel_metrics = pd.read_csv(list_metrics_C2[i])\n",
    "    sample_metrics = pd.read_csv(list_samples_C2[i])\n",
    "    sample_metrics = sample_metrics.drop(labels='Class', axis=1) # removing the column 'Class' from the dataframe\n",
    "    sample_classes = pd.read_csv(list_classes_C2[i])\n",
    "    \n",
    "    smp_metrics = np.float32(sample_metrics)\n",
    "    smp_classes = np.float32(sample_classes)\n",
    "    smp_classes = np.ravel(smp_classes) # converting from column-vector to 1d array (expected by the classifier)\n",
    "    pixels_metrics = np.float32(pixel_metrics)\n",
    "    \n",
    "    # ------------------------- SPLITTING THE SAMPLES INTO TRAINING AND TESTING DATASETS -------------------------\n",
    "    \n",
    "    # This scikit-learn function separates the datasets in train and test samples\n",
    "    smp_metrics_train, smp_metrics_test, smp_classes_train, smp_classes_test = train_test_split(smp_metrics, smp_classes, \n",
    "                                                                                                test_size=0.3)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=300, min_samples_leaf = 5, max_features = 5, n_jobs=-1, oob_score=True)\n",
    "    rf.fit(smp_metrics_train, smp_classes_train) # X and Y parameters (as recognized by the classifier)\n",
    "    \n",
    "    Y_train_pred = rf.predict(smp_metrics_train) # Classifies the training samples (resubstitution validation technique)\n",
    "    acc_train = accuracy_score(smp_classes_train, Y_train_pred) # Computes the accuracy\n",
    "    print('    Overall accuracy (resubst): ' + str(round(acc_train,4)))\n",
    "    #print('-------------------')\n",
    "    \n",
    "    Y_test_pred = rf.predict(smp_metrics_test) # Classifies the testing samples (hold-out validation technique)\n",
    "    acc_test = accuracy_score(smp_classes_test, Y_test_pred) # Computes the accuracy\n",
    "    print('    Overall accuracy (holdout): ' + str(round(acc_test,4)))\n",
    "    confusion_pred = pd.crosstab(Y_test_pred, smp_classes_test, rownames=['Pred'], colnames=['Actual'], \n",
    "                                 margins=False, margins_name=\"Total\") # confusion matrix for the testing dataset\n",
    "    \n",
    "    confusion_pred.loc['Accuracies','OA_Resubs'] = acc_train\n",
    "    confusion_pred.loc['Accuracies','OA_Holdout'] = acc_test\n",
    "\n",
    "    # -----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    class_pred = rf.predict(pixels_metrics) #classification of all pixels\n",
    "    \n",
    "    imgPath = \"DATA/ee_export/\" + filenames_C2[i] + \".tif\"\n",
    "    example_img = gdal.Open(imgPath)\n",
    "\n",
    "    Nrows = example_img.RasterYSize\n",
    "    Ncols = example_img.RasterXSize\n",
    "    GeoTransform = example_img.GetGeoTransform()\n",
    "    Projection = example_img.GetProjection()\n",
    "\n",
    "    example_img = None\n",
    "\n",
    "    classif_array = np.reshape(class_pred, (Nrows-6, Ncols-6))\n",
    "\n",
    "    # In this study, we disconsidered the border pixels (3-pixel length). Therefore, we need to adjust \n",
    "    # the array to follow the same characteristics of the example image (GeoTranform and Projection)\n",
    "    classif_array_adjusted = np.empty((Nrows, Ncols), np.float32)\n",
    "    classif_array_adjusted[3:Nrows-3, 3:Ncols-3] = classif_array\n",
    "\n",
    "    # Writing the classification product and the confusion matrix to files\n",
    "    if (write_files == 'YES'):\n",
    "        filename_map = dir_output_metrics + filenames_C2[i] + \"_Metrics_RFclassification.tif\"\n",
    "        filename_matrix = dir_output_metrics + filenames_C2[i] + \"_Metrics_RFconfusionMatrix.csv\"\n",
    "\n",
    "        try:\n",
    "            # Classification map\n",
    "            Write_GeoTiff(classif_array_adjusted, filename_map, Nrows, Ncols, GeoTransform, Projection)\n",
    "            \n",
    "            # Confusion matrix\n",
    "            confusion_pred.to_csv(filename_matrix, sep=',', index=True, header=True, index_label='Pred/Actual', \n",
    "                                  encoding='utf-8-sig')\n",
    "            print(\"    The products were written to file!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
