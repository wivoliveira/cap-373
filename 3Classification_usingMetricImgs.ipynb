{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> <center> Exploiting Sentinel-1 imagery time series to detect grasslands in northern Brazil tropical plains</center> </h1>\n",
    "<h3> <center> Part 3 - Classification </center> </h3>\n",
    "<center> Arian Ferreira Carneiro </center>\n",
    "<center>Willian Vieira de Oliveira </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from osgeo import gdal, gdal_array\n",
    "#from osgeo import osr\n",
    "from numpy import genfromtxt\n",
    "\n",
    "# Load scikit's random forest classifier library\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "#import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Would you like to write the classification maps to files? ['YES', 'NO']\n",
    "write_files = 'YES'\n",
    "\n",
    "# Output directory\n",
    "dir_output = \"OUTPUT/Classification_metrics_imgs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files that contain the metric images and samples\n",
    "\n",
    "#### Metric images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories to the metric images\n",
    "dir_NL_MeanImg = \"DATA/ee_export/Metric_images/NL_MeanImg.tif\"\n",
    "dir_NL_StdImg = \"DATA/ee_export/Metric_images/NL_StdImg.tif\"\n",
    "dir_NL_SumImg = \"DATA/ee_export/Metric_images/NL_SumImg.tif\"\n",
    "dir_NL_MinImg = \"DATA/ee_export/Metric_images/NL_MinImg.tif\"\n",
    "dir_NL_MaxImg = \"DATA/ee_export/Metric_images/NL_MaxImg.tif\"\n",
    "dir_NL_AmpImg = \"DATA/ee_export/Metric_images/NL_AmplitudeImg.tif\"\n",
    "dir_NL_CoVarImg = \"DATA/ee_export/Metric_images/NL_CoefVariationImg.tif\"\n",
    "dir_NL_FstSlopeImg = \"DATA/ee_export/Metric_images/NL_FirstSlopeImg.tif\"\n",
    "\n",
    "dir_Ratio_MeanImg = \"DATA/ee_export/Metric_images/Ratio_MeanImg.tif\"\n",
    "dir_Ratio_StdImg = \"DATA/ee_export/Metric_images/Ratio_StdImg.tif\"\n",
    "dir_Ratio_SumImg = \"DATA/ee_export/Metric_images/Ratio_SumImg.tif\"\n",
    "dir_Ratio_MinImg = \"DATA/ee_export/Metric_images/Ratio_MinImg.tif\"\n",
    "dir_Ratio_MaxImg = \"DATA/ee_export/Metric_images/Ratio_MaxImg.tif\"\n",
    "dir_Ratio_AmpImg = \"DATA/ee_export/Metric_images/Ratio_AmplitudeImg.tif\"\n",
    "dir_Ratio_CoVarImg = \"DATA/ee_export/Metric_images/Ratio_CoefVariationImg.tif\"\n",
    "dir_Ratio_FstSlopeImg = \"DATA/ee_export/Metric_images/Ratio_FirstSlopeImg.tif\"\n",
    "\n",
    "dir_RGI_MeanImg = \"DATA/ee_export/Metric_images/RGI_MeanImg.tif\"\n",
    "dir_RGI_StdImg = \"DATA/ee_export/Metric_images/RGI_StdImg.tif\"\n",
    "dir_RGI_SumImg = \"DATA/ee_export/Metric_images/RGI_SumImg.tif\"\n",
    "dir_RGI_MinImg = \"DATA/ee_export/Metric_images/RGI_MinImg.tif\"\n",
    "dir_RGI_MaxImg = \"DATA/ee_export/Metric_images/RGI_MaxImg.tif\"\n",
    "dir_RGI_AmpImg = \"DATA/ee_export/Metric_images/RGI_AmplitudeImg.tif\"\n",
    "dir_RGI_CoVarImg = \"DATA/ee_export/Metric_images/RGI_CoefVariationImg.tif\"\n",
    "dir_RGI_FstSlopeImg = \"DATA/ee_export/Metric_images/RGI_FirstSlopeImg.tif\"\n",
    "\n",
    "dir_VH_MeanImg = \"DATA/ee_export/Metric_images/VH_MeanImg.tif\"\n",
    "dir_VH_StdImg = \"DATA/ee_export/Metric_images/VH_StdImg.tif\"\n",
    "dir_VH_SumImg = \"DATA/ee_export/Metric_images/VH_SumImg.tif\"\n",
    "dir_VH_MinImg = \"DATA/ee_export/Metric_images/VH_MinImg.tif\"\n",
    "dir_VH_MaxImg = \"DATA/ee_export/Metric_images/VH_MaxImg.tif\"\n",
    "dir_VH_AmpImg = \"DATA/ee_export/Metric_images/VH_AmplitudeImg.tif\"\n",
    "dir_VH_CoVarImg = \"DATA/ee_export/Metric_images/VH_CoefVariationImg.tif\"\n",
    "dir_VH_FstSlopeImg = \"DATA/ee_export/Metric_images/VH_FirstSlopeImg.tif\"\n",
    "\n",
    "dir_VV_MeanImg = \"DATA/ee_export/Metric_images/VV_MeanImg.tif\"\n",
    "dir_VV_StdImg = \"DATA/ee_export/Metric_images/VV_StdImg.tif\"\n",
    "dir_VV_SumImg = \"DATA/ee_export/Metric_images/VV_SumImg.tif\"\n",
    "dir_VV_MinImg = \"DATA/ee_export/Metric_images/VV_MinImg.tif\"\n",
    "dir_VV_MaxImg = \"DATA/ee_export/Metric_images/VV_MaxImg.tif\"\n",
    "dir_VV_AmpImg = \"DATA/ee_export/Metric_images/VV_AmpImg.tif\"\n",
    "dir_VV_CoVarImg = \"DATA/ee_export/Metric_images/VV_CoefVariationImg.tif\"\n",
    "dir_VV_FstSlopeImg = \"DATA/ee_export/Metric_images/VV_FirstSlopeImg.tif\"\n",
    "\n",
    "# Directories to the sample files\n",
    "dir_NL_samples = \"OUTPUT/NL_AllSamples_metrics.csv\"\n",
    "dir_NL_classes = \"OUTPUT/NL_AllSamples_classes.csv\"\n",
    "\n",
    "dir_Ratio_samples = \"OUTPUT/Ratio_AllSamples_metrics.csv\"\n",
    "dir_Ratio_classes = \"OUTPUT/Ratio_AllSamples_classes.csv\"\n",
    "\n",
    "dir_RGI_samples = \"OUTPUT/RGI_AllSamples_metrics.csv\"\n",
    "dir_RGI_classes = \"OUTPUT/RGI_AllSamples_classes.csv\"\n",
    "\n",
    "dir_VH_samples = \"OUTPUT/VH_AllSamples_metrics.csv\"\n",
    "dir_VH_classes = \"OUTPUT/VH_AllSamples_classes.csv\"\n",
    "\n",
    "dir_VV_samples = \"OUTPUT/VV_AllSamples_metrics.csv\"\n",
    "dir_VV_classes = \"OUTPUT/VV_AllSamples_classes.csv\"\n",
    "\n",
    "# Lists of the directories\n",
    "filenames = ['NL', 'Ratio', 'RGI', 'VH', 'VV']\n",
    "filenames_metrics = ['Mean', 'Std', 'Sum', 'Min', 'Max', 'Amp', 'Covar', 'FstSlope']\n",
    "\n",
    "list_NL_metrics = [dir_NL_MeanImg, dir_NL_StdImg, dir_NL_SumImg, dir_NL_MinImg, dir_NL_MaxImg, dir_NL_AmpImg, dir_NL_CoVarImg, dir_NL_FstSlopeImg]\n",
    "list_Ratio_metrics = [dir_Ratio_MeanImg, dir_Ratio_StdImg, dir_Ratio_SumImg, dir_Ratio_MinImg, dir_Ratio_MaxImg, dir_Ratio_AmpImg, dir_Ratio_CoVarImg, dir_Ratio_FstSlopeImg]\n",
    "list_RGI_metrics = [dir_RGI_MeanImg, dir_RGI_StdImg, dir_RGI_SumImg, dir_RGI_MinImg, dir_RGI_MaxImg, dir_RGI_AmpImg, dir_RGI_CoVarImg, dir_RGI_FstSlopeImg]\n",
    "list_VH_metrics = [dir_VH_MeanImg, dir_VH_StdImg, dir_VH_SumImg, dir_VH_MinImg, dir_VH_MaxImg, dir_VH_AmpImg, dir_VH_CoVarImg, dir_VH_FstSlopeImg]\n",
    "list_VV_metrics = [dir_VV_MeanImg, dir_VV_StdImg, dir_VV_SumImg, dir_VV_MinImg, dir_VV_MaxImg, dir_VV_AmpImg, dir_VV_CoVarImg, dir_VV_FstSlopeImg]\n",
    "\n",
    "list_metric_imgs = [list_NL_metrics, list_Ratio_metrics, list_RGI_metrics, list_VH_metrics, list_VV_metrics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_samples = [dir_NL_samples, dir_Ratio_samples, dir_RGI_samples, dir_VH_samples, dir_VV_samples]\n",
    "list_classes = [dir_NL_classes, dir_Ratio_classes, dir_RGI_classes, dir_VH_classes, dir_VV_classes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary functions\n",
    "\n",
    "### Function to write each classification map to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "\n",
    "def openImage(filepath):\n",
    "    data = gdal.Open(filepath)\n",
    "    return data\n",
    "\n",
    "\n",
    "def Write_GeoTiff(file, filename, Nrows, Ncols, geotransform, projection):\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    \n",
    "    dataset_output = driver.Create(filename, Ncols, Nrows, 1, gdal.GDT_Float32)\n",
    "    dataset_output.GetRasterBand(1).WriteArray(file)\n",
    "    \n",
    "    if geotransform is not None:\n",
    "        gt = list(geotransform)\n",
    "        dataset_output.SetGeoTransform(tuple(gt))\n",
    "    dataset_output.SetProjection(projection)\n",
    "    \n",
    "    dataset_output = None\n",
    "\n",
    "    \n",
    "def Write_dataframe(df, filename):\n",
    "    try:\n",
    "        df.to_csv(filename, sep=',', index=False, encoding='utf-8-sig')\n",
    "        print(\"    The dataframe was written to file!\")\n",
    "    except Exception as e:\n",
    "        print(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "In this procedure, we convert the metric images to flatten arrays and combine them in an unique dataframe per data type (e.g., NL, VV, VH)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organizing the  NL  data...\n",
      "  Processing metric images...\n",
      "    The dataframe was written to file!\n",
      "\n",
      "\n",
      "Organizing the  Ratio  data...\n",
      "  Processing metric images...\n",
      "    The dataframe was written to file!\n",
      "\n",
      "\n",
      "Organizing the  RGI  data...\n",
      "  Processing metric images...\n",
      "    The dataframe was written to file!\n",
      "\n",
      "\n",
      "Organizing the  VH  data...\n",
      "  Processing metric images...\n",
      "    The dataframe was written to file!\n",
      "\n",
      "\n",
      "Organizing the  VV  data...\n",
      "  Processing metric images...\n",
      "    The dataframe was written to file!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_metrics = []\n",
    "#for i in range(1):\n",
    "for i in range(len(filenames)):\n",
    "    print(\"Organizing the \", filenames[i], \" data...\")\n",
    "    \n",
    "    df = pd.DataFrame(columns=filenames_metrics)\n",
    "    \n",
    "    print(\"  Processing metric images...\")\n",
    "    for m in range(len(filenames_metrics)):    \n",
    "        datacube = openImage(list_metric_imgs[i][m])\n",
    "\n",
    "        Nrows = datacube.RasterYSize - 6 # We do not consider border pixels. We removed both the first and the last three rows.\n",
    "        Ncols = datacube.RasterXSize - 6 # We do not consider border pixels. We removed both the first and the last three columns.\n",
    "\n",
    "        arr = datacube.ReadAsArray(3, 3, Ncols, Nrows) # xoff, yoff, xcount, ycount\n",
    "\n",
    "        df[filenames_metrics[m]] = arr.flatten()\n",
    "        \n",
    "        # Closing image file\n",
    "        datacube = None\n",
    "    \n",
    "    if (write_files == 'YES'):\n",
    "        filename = dir_output + filenames[i] + '_metrics.csv'\n",
    "        Write_dataframe(df, filename)\n",
    "        \n",
    "        list_metrics.append(filename)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification: using basic metrics\n",
    "\n",
    "In this procedure, we perform the classification of the data cube considering the metrics computed for the time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying the  NL  data cube...\n",
      "    Overall accuracy (resubst): 0.911\n",
      "    Overall accuracy (holdout): 0.8398\n",
      "    The products were written to file!\n",
      "\n",
      "\n",
      "Classifying the  Ratio  data cube...\n",
      "    Overall accuracy (resubst): 0.8795\n",
      "    Overall accuracy (holdout): 0.6429\n",
      "    The products were written to file!\n",
      "\n",
      "\n",
      "Classifying the  RGI  data cube...\n",
      "    Overall accuracy (resubst): 0.8687\n",
      "    Overall accuracy (holdout): 0.6458\n",
      "    The products were written to file!\n",
      "\n",
      "\n",
      "Classifying the  VH  data cube...\n",
      "    Overall accuracy (resubst): 0.913\n",
      "    Overall accuracy (holdout): 0.832\n",
      "    The products were written to file!\n",
      "\n",
      "\n",
      "Classifying the  VV  data cube...\n",
      "    Overall accuracy (resubst): 0.9052\n",
      "    Overall accuracy (holdout): 0.8263\n",
      "    The products were written to file!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#for i in range(1):\n",
    "for i in range(len(filenames)):\n",
    "    print(\"Classifying the \", filenames[i], \" data cube...\")\n",
    "    \n",
    "    pixel_metrics = pd.read_csv(list_metrics[i])\n",
    "    sample_metrics = pd.read_csv(list_samples[i])\n",
    "    sample_metrics = sample_metrics.drop(labels='Class', axis=1) # removing the column 'Class' from the dataframe\n",
    "    sample_classes = pd.read_csv(list_classes[i])\n",
    "    \n",
    "    smp_metrics = np.float32(sample_metrics)\n",
    "    smp_classes = np.float32(sample_classes)\n",
    "    smp_classes = np.ravel(smp_classes) # converting from column-vector to 1d array (expected by the classifier)\n",
    "    pixels_metrics = np.float32(pixel_metrics)\n",
    "    \n",
    "    # ------------------------- SPLITTING THE SAMPLES INTO TRAINING AND TESTING DATASETS -------------------------\n",
    "    \n",
    "    # This scikit-learn function separates the datasets in train and test samples\n",
    "    smp_metrics_train, smp_metrics_test, smp_classes_train, smp_classes_test = train_test_split(smp_metrics, smp_classes, \n",
    "                                                                                                test_size=0.3)\n",
    "    \n",
    "    rf = RandomForestClassifier(n_estimators=300, min_samples_leaf = 5, max_features = 5, n_jobs=-1, oob_score=True)\n",
    "    rf.fit(smp_metrics_train, smp_classes_train) # X and Y parameters (as recognized by the classifier)\n",
    "    \n",
    "    Y_train_pred = rf.predict(smp_metrics_train) # Classifies the training samples (resubstitution validation technique)\n",
    "    acc_train = accuracy_score(smp_classes_train, Y_train_pred) # Computes the accuracy\n",
    "    print('    Overall accuracy (resubst): ' + str(round(acc_train,4)))\n",
    "    #print('-------------------')\n",
    "    \n",
    "    Y_test_pred = rf.predict(smp_metrics_test) # Classifies the testing samples (hold-out validation technique)\n",
    "    acc_test = accuracy_score(smp_classes_test, Y_test_pred) # Computes the accuracy\n",
    "    print('    Overall accuracy (holdout): ' + str(round(acc_test,4)))\n",
    "    confusion_pred = pd.crosstab(Y_test_pred, smp_classes_test, rownames=['Pred'], colnames=['Actual'], \n",
    "                                 margins=False, margins_name=\"Total\") # confusion matrix for the testing dataset\n",
    "    \n",
    "    confusion_pred.loc['Accuracies','OA_Resubs'] = acc_train\n",
    "    confusion_pred.loc['Accuracies','OA_Holdout'] = acc_test\n",
    "\n",
    "    # -----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    class_pred = rf.predict(pixels_metrics) #classification of all pixels\n",
    "    \n",
    "    imgPath = \"DATA/ee_export/\" + filenames[i] + \".tif\"\n",
    "    example_img = gdal.Open(imgPath)\n",
    "\n",
    "    Nrows = example_img.RasterYSize\n",
    "    Ncols = example_img.RasterXSize\n",
    "    GeoTransform = example_img.GetGeoTransform()\n",
    "    Projection = example_img.GetProjection()\n",
    "\n",
    "    example_img = None\n",
    "\n",
    "    classif_array = np.reshape(class_pred, (Nrows-6, Ncols-6))\n",
    "\n",
    "    # In this study, we disconsidered the border pixels (3-pixel length). Therefore, we need to adjust \n",
    "    # the array to follow the same characteristics of the example image (GeoTranform and Projection)\n",
    "    classif_array_adjusted = np.empty((Nrows, Ncols), np.float32)\n",
    "    classif_array_adjusted[3:Nrows-3, 3:Ncols-3] = classif_array\n",
    "\n",
    "    # Writing the classification product and the confusion matrix to files\n",
    "    if (write_files == 'YES'):\n",
    "        filename_map = dir_output + filenames[i] + \"_Metrics_RFclassification.tif\"\n",
    "        filename_matrix = dir_output + filenames[i] + \"_Metrics_RFconfusionMatrix.csv\"\n",
    "\n",
    "        try:\n",
    "            # Classification map\n",
    "            Write_GeoTiff(classif_array_adjusted, filename_map, Nrows, Ncols, GeoTransform, Projection)\n",
    "            \n",
    "            # Confusion matrix\n",
    "            confusion_pred.to_csv(filename_matrix, sep=',', index=True, header=True, index_label='Pred/Actual', \n",
    "                                  encoding='utf-8-sig')\n",
    "            print(\"    The products were written to file!\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "    \n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
